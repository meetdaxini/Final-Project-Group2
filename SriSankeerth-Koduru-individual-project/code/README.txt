To effectively utilize the code for the facebook/bart-large-xsum model trained on the Multi_News dataset, follow these steps:

1)NLP_Project_Train_Multi_News_Final.py:
Execute the NLP_Project_Train_Multi_News_Final.py script. This will generate two crucial artifacts:
multi_label_test.csv: This file serves as the test set for evaluation purposes.
best_model_Multi_News_final.pt: This file represents the optimal model trained on the Multi_News dataset.

2)NLP_Project_Test_Multi_News_Final.py:
Link for the model: https://drive.google.com/file/d/1AYZpvU0LZTBuU3gpVAqaF9qGU4hU0P7o/view?usp=sharing
Link for the dataset: https://drive.google.com/file/d/1cyVg9TI312bR0jPDblGc82hENMTn6vWe/view?usp=sharing
Utilize the multi_label_test.csv dataset as the testing set.
Validate the performance of the model using best_model_Multi_News_final.pt.

3)Generating_Text_Multi_News_Final.py:
Link for the model: https://drive.google.com/file/d/1AYZpvU0LZTBuU3gpVAqaF9qGU4hU0P7o/view?usp=sharing
Employ best_model_Multi_News_final.pt to execute the desired functionality.
